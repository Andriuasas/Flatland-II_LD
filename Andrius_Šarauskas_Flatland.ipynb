
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(128, activation='relu'))\n",
        "    model.add(layers.Dense(5, activation='softmax'))  # Assuming 5 classes\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "eWHDxRY6tdQd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Training the model"
      ],
      "metadata": {
        "id": "8bQCqohTyCpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile and train the model\n",
        "input_shape = (52, 52, 1)  # Height, width, channels\n",
        "model = create_cnn_model(input_shape)\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Reshape data for training\n",
        "X_train = X_train.reshape(-1, 52, 52, 1)  # Add channel dimension\n",
        "X_val = X_val.reshape(-1, 52, 52, 1)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpcNrv9KtgqG",
        "outputId": "773e1ca3-b03d-4b58-d4cd-c9119076d6b6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.7246 - loss: 0.7304 - val_accuracy: 0.9843 - val_loss: 0.1339\n",
            "Epoch 2/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9818 - loss: 0.1340 - val_accuracy: 0.9830 - val_loss: 0.1242\n",
            "Epoch 3/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9829 - loss: 0.1172 - val_accuracy: 0.9842 - val_loss: 0.1214\n",
            "Epoch 4/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9831 - loss: 0.1023 - val_accuracy: 0.9850 - val_loss: 0.1128\n",
            "Epoch 5/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9829 - loss: 0.0901 - val_accuracy: 0.9854 - val_loss: 0.1139\n",
            "Epoch 6/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9845 - loss: 0.0774 - val_accuracy: 0.9823 - val_loss: 0.1224\n",
            "Epoch 7/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9824 - loss: 0.0743 - val_accuracy: 0.9855 - val_loss: 0.1226\n",
            "Epoch 8/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9848 - loss: 0.0621 - val_accuracy: 0.9810 - val_loss: 0.1374\n",
            "Epoch 9/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9855 - loss: 0.0530 - val_accuracy: 0.9811 - val_loss: 0.1435\n",
            "Epoch 10/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9865 - loss: 0.0455 - val_accuracy: 0.9818 - val_loss: 0.1597\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Print all predictions from model"
      ],
      "metadata": {
        "id": "HxWtQc91yJrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "val_loss, val_accuracy = model.evaluate(X_val, y_val)\n",
        "print(f'Validation accuracy: {val_accuracy:.4f}')\n",
        "\n",
        "X_eval_sobel = apply_sobel_with_padding(X_eval)  # Apply Sobel to test data\n",
        "X_eval_sobel = X_eval_sobel.reshape(-1, 52, 52, 1)  # Reshape for the model\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(X_eval_sobel)\n",
        "\n",
        "# Convert predictions to class labels\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Convert the predictions to a single string of numbers\n",
        "predicted_string = ''.join(map(str, predicted_classes))\n",
        "\n",
        "# Print the result\n",
        "print(predicted_string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Dsfo9DmtnY7",
        "outputId": "3fd03594-2fe6-41b9-9e00-61a7ed305355"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9819 - loss: 0.1626\n",
            "Validation accuracy: 0.9818\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "4423311121200031120323243422320231030133000141002131142104442032331101433301021130310402300133133241310201103123123020013140430002033310223233321432123024323413013414324101314434143430140403400241310113131114113243131104031343231140230032300041224040124321200231411233220324132301120100122331433031321104222033131221204010403100032433304112310322110032132300221022130423241124030104302103331423023133311114414110430422123342122313001422211041102033322302303123331030442100101222322302010104122004332111200304314322410112013421212121430201110141301213401334231220330321201210230343303101212314332133213013002231044242334014201110241233142204341021332221123130301031334440342311214130112134122131121040111021221211302324211112013410032230322301421400301133411334100331101011014241222200324231211440303402123234310201110013303242004342210331011133120322310411321413431142010013210220134312122001330011014211132300413014220302420033122120140410423434202141413424213202000344133103102301013100231443133002232330134033100231033122421032303001320411011100133143233101022141232443103124330231224401133020114122144204340012210413423240010033422421213232333444313402312211311201334221233312413302100023141242212220143303220131044411213233303322220013344341222143003243112111432032243121001212230124233211220212222110132312343033414331130244143343222043013202103242033001044141420221304012034124123433131010341014320312101243431334101300110314131214111212113043113312333113321414311031432241022240202141410223433110112342131313100021111121231223002313344112101000202201103123220034234032424014141024231041221222112112142323122111313211224331302324341020301031313340110314331203341012113010101342003410113342131402324440224324112434424012423411203030311332212312031302312203344020131312030012223343313324303231313410311041231214341321322403034300023314022224341022220011020100103301243010113413102321301332011011321213402034331124200334331221224231334022140112331104400033122034341432031340100434113331214132414200110442120211103343222100341133314002020100230033333024343432441141440432423300301001410330213001032220403342303423410124133211303310002202243222111201322201131103212413213223330301423203131021113124041323144002313302032121021011113231102210244120234221312312314111201133444331112232412011031432021132233310430314311124111212313241242212013301313121214132431412330220300213440123404232443420331422120413124032122102221302423321334040012222212213303303424034303032132210330231104043304313314003412133412221133221213211202113130312422220220323241313020414111414222132223020321004403431433130224413302014104212311000222232002312244134110130123020121103100322032123314122312402332210340100203221023122121110113114034031232104201123112344004412214101123330031400330432201411112303303310403202313201040132214230331312020031203431342423413123230131200243343303210001311341112314303324201431310212432320121200231432210211000133403330103121432113410144311340123022200130302222321013401341030104011122443213433010121313124334403324311441440140210313300143114001433032311331101004202230230412332314311241100313301140014440030203012212232113040224230101121221033323322113121110033242324021142122413214223112021010131130211033011401233312431141010422132102411412314110444110023303003041413123013112122202102211323343321321302141234142210223210313122303221000433311202102331202423043131000013303423314413231114203022240022302104231222031001320222221303322421310431210142441340112231324042011313322441123120312014243311330133334322112302323104224213021110000312201224122343243042442041433323034311310310230344310331144021141331231234103023312101420031233134144333314212032402011222121212030342334133213113121411033210022232424340032220411404022130331222110022201231134201302120213110113242331133041303031440200301121013141203124321310322241422103200101030423431120444102231414440021201132112431032300022020300213440320434341112212110114141231322140100134102233431224112021103002131113432440330113321120312222341040423430332314212221241200202003233303214240300000041221110343342433131103411133000341213143433423433211203113041340331300431413432410312222123033121323103434442422104241230014024241012330011321120132321342341301302434033201410344010312202013121332031012141022142023143322133101241340104323141204113312324424431300330424302122300123213421010303314121213100101321310131214403110313313102013333232032412304333144131323123133200210103311432000123140313003431031221432414413430410312404120044103102340132411233133233301400032311212133224134220130310430231301222310112131021022441132013110103230311420203133444321000341211111441314132213241011310321413133210034000012101212332112111043003110332421241342220003242220103001024220221412301100000411412332211311343303043121320003232201412213012241220401420333321320311122420211310321133204220402333422202403310001431332100431311112030112422201400242223240231404324302133130331121424113402133122203320221101300101433320433111301123110312230232230014444031402112120311014210114331313320330331121004001110333402301430441122301131222121431230133320113311301432241102304443313414100222034242301223244334231312114314220200434311040123020323322201410333114221210220401131012412334334122232121110031412102120444001022111211230321313310332341101343331102140114210113043443144041311041240413012311321031002323044014130133132212201342211222421431324302210424214013342411230310101342124011302014200002341333132324341211031021414110221222212323123131234121140141413010041242013110433021240303234323121200431204201113333034021020302221012042304000111331003012013422300034101010043401410331013032231022240232312011320243113111343231332331020103203222211332332402301112012022213440201241041300112400023112114030122244432031311002224333321331311434420112303114301034311201422004401312141101204122301013232102211402414111123410013044133132111001122423443223320023220342321300103331122034312323202122143403322020033112413100332102342201203310333312104122444413313020232232232214121342044411103420430321412031113112230124212100140400312433020012043201202333101213312104423132122433320043232112000430131301430001320213130123130000331211330440012121413010114113342142112314432221320022213101104140332122211011321142221011403013131223114202231104023041030401014331422033320242241033330323222111033322201342132433134200420132240030243323141122130021434033213104412011023140133431303032130213434412213002111211310311141414021000412202434110403011013033123032123412214331101214434232211141321202301221232234323141122120303102301004310331141000011032210301023102003113113120134111210241332033221304322031330123141012013131322022331010112103204142041212240332304421334310121004322010143324340003134111231311001202331132013210244222002331404213321101404043013221131411131144100144310033224234210311111342220342114311131233331444133423200200312032410312104432423340022320234123321212412432324323140133210130411230313223111304301434242132321224134121133023431301340230422224321113402221324011232111203101434443000140130103022012423442200234212312344420314043210241302011221324022100131233123413242130434232230414140133324013130134200423143133202122230231413132131312021430103011001323141024404134123402110321402031244422103311131043121222111132441012132423211123134202202334020200212322232123242111423310114300030313211211410242314113320334414302120023122134244443443012130041113331303210234002123124112221443313440132222321220214204024000032342224214103113322133233122101111123224341231310312031243134430111312031113034114102102000000033420332031122000230022020302044041400321101410301012440014322213142032322431043212011311140203221333100312434312340021121331141334222234342320102330330123004002201404024233431211414133311110101003221234203341334131110312313443003434100144123133002211221320331044310002332342122033214111331123123001412002030312134004304221323224144111111023134443030401443113022144312222030041320102241113421310121121004011323221424431043203433332131213323201003131101314100101233103402241301104330014434310132002132323421220201140101044200221230022312411220401433104132120314213211232342211233000114112302203424421121210203211433312332212210240112241321010022211220112420410124042102221201322311214414341233042221411423411330013102201322023101411302214313201402101330221340100231430120433134230124311001113011143231233323221144240220312210423310123101234423212014143102124103012204001122234001004210443430423011323103241242142201231033312312311100110022324313433333332011303140112300203121232232413343433233301242333332010210003443104112340111014233402300321002240113431341102122012210102413212011101102203232441423002021011210023042230034412231100014122024414214113433343223132031420321012130443111144323430403242301103041131210221321341300331141121333213333332001334440131124200013332011130331014331442233311320231103424231240041400300232141434333142141101402343442141333002220110043420332302310312220224322113442420102011024122133211134411310141222111120131123003403343340213142031333140204004210230214012243213134130323223112312113123011112211041222100312221314400303402430334202232333441323232031011110141023210314034222303232310324303412121432002011321422011340013444334421410302123411002321132012213133123101311332211430432310303144431012031010012120223343302112431143122132231044401312110111310410001311412103130000002332024343202100331221302100413014340041243133423011123431210000223044403111011002231430101344142140444314104113222134132331030443120122303123330244301201233101424033323001011121211220131304411122443203233414034014200103024011331101123103143301244104112214311333004031312231221123013122120414010303241033014111023232000132410433230132210231124233010434313200212130311223012040124333121304424414123011100214032200024133230233222333234321010334122113330001202011413421222010012324202300401024143002014131332304430330302332300130402122412321223112203134134232230232323030433401142020311132432411211220342233222103431000403223303111422013211200210313\n"
          ]
        }
      ]
    }
  ]
}
